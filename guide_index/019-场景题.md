# 场景题

## ✅如何实现百万数据的导入导出功能

1、明确技术栈为esay-excel

（1）速度快

（2）解决poi造成的内存溢出的问题

2、多线程处理sheet页

3、多线程处理数据

4、批量插入

5、换一种思路解决并发安全问题，每次处理数据都传入新的listener，从而减少并发安全类的使用

参考文章：https://juejin.cn/post/7287144182967353398#heading-45



## ⚠️如何实现一个抽奖系统

封装一个抽奖组件，内部使用lua脚本，在一个脚本中实现，库存的检查、扣减等动作。





## ✅你们是如何关闭到期的订单的，比如30分钟未支付，关单

我先说一下可能的几种方案，当然没有最好的方案，只有最适合的方案。

| 方案名称            | 实现原理                                             | 优点                                                         | 缺点                                                         |
| ------------------- | ---------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 定时任务            | 通过调度平台周期性扫描到期订单并执行关单操作         | 实现简单，易于上手；基于成熟的调度框架，可靠性较高           | 时间不精准，可能存在延迟；无法有效处理大订单量，对数据库造成较大压力 |
| 延迟消息队列        | 利用消息队列的延迟消息功能，在订单创建时发送延迟消息 | 解耦系统，提高可扩展性和可维护性；支持高并发处理，能够应对大订单量场景 | 需要引入额外的消息队列中间件，增加系统复杂性；延迟消息的精度可能受影响 |
| Redis过期监听       | 利用Redis的键过期通知功能执行关单操作                | Redis性能高，适用于实时性要求较高的场景；无需额外引入消息队列等中间件 | 过期通知并非实时触发，可能存在延迟；需要手动实现消息重试和兜底机制 |
| JDK自带的DelayQueue | 将订单包装为实现了Delayed接口的对象放入DelayQueue中  | 无需依赖外部资源，实现简单；JDK原生支持，稳定性高            | 适用于单机场景，分布式环境下需要额外处理数据一致性问题；内存限制 |
| 时间轮              | 使用时间轮数据结构，周期性执行到期任务               | 时间复杂度低，插入和删除操作效率高；适用于分布式场景         | 实现复杂，需要自行开发或引入第三方库；内存限制；机器重启会导致数据丢失 |

我在工作中，用得最多的是`延迟消息队列`这个方案，用得是MQ的消息队列，有时候还会配合定时任务扫表。





## ✅一个订单，在超时关闭的瞬间，客户支付了，并且支付成功了，这种情况你怎么处理

按道理有2种推进的方式：

1、让订单成功

2、让支付退款

我在xxxx工作时，也遇到过这种情况，当时的做法就是给客户退款了，并且会通知客服联系客户说明情况。那为什么要给客户退款呢？

一方面，订单的`已取消`状态一般是终态，终态是不能进行流转操作的。另一方面订单取消，一般不仅仅只是取消这么一个操作，万一还有其他操作呢？比如这笔订单，参与了营销活动，当订单取消的时候，券啊，积分啊啥的都已经退回去了，这个时候再手动加回来，处理难度是非常大的。当然用户是上帝，我也被要求让订单成功的情况，那种就是人工智能了。



## ✅线上有个Java应用突然变慢了，你怎么排查？

0、暴露问题

上报主管，表明有生产问题

1、确认问题

变慢了，那么慢了多少？

比如响应时间从原来的500ms增加到5000ms。

2、分析日志

应用日志显示大量GC警告

3、分析监控数据

比如查看`grafana`

JVM监控显示老年代内存使用率高，FulGC频繁

4、分析线程

Thread Dump显示多个线程在等待数据库连接。

5、分析数据库

发现数据库连接池耗尽，大量慢查询。

6、审查代码

最近的代码变更引入了一个无效的数据库连接释放。

7、找到根本原因

由于连接未正确释放，导致连接池耗尽，引发了大量等待，进而导致内存积压和频繁GC。

8、解决方案

修复连接释放的bug，优化相关SQL，增加连接池大小。

9、验证和监控

修复后，响应时间恢复正常，GC频率降低

10、总结归档

将排查过程总结归档，形成公司文档资产



## ✅敏感词过滤如何实现呢？

1、构建词库

2、识别敏感词

（1）基于简单字符串匹配的过滤

（2）基于Trie树的高效匹配

（3）DFA算法

开源框架：sensitive-word

（4）引入大模型

（5）引入收费服务，如华为敏感词识别服务

3、过滤



## ✅数据脱敏怎么做？比如身份证号码、电话等

1、明确脱敏需求：根据业务需求和安全要求，明确哪些数据需要脱敏以及脱敏的程度。
2、选择脱敏方法：根据数据的特性和脱敏需求选择合适的脱敏方法。

常见的脱敏方法包括替换法、掩码法、加密法、数据扰动等。

3、设计脱敏规则：根据选定的脱敏方法设计具体的脱敏规则，如替换法中的替换位置和替换字符等。
4、实施脱敏操作：使用数据库管理工具、编程语言或专门的脱敏工具对敏感数据进行脱敏处理。
5、验证脱敏效果：对脱敏后的数据进行验证，确保脱敏效果符合预期且不影响数据的正常使用。



## ✅缓存如何预热？

1、启动过程中预热

@PostConstruct

InitializingBean

2、定时任务

3、用时加载

4、使用开源框架，比如caffeine等







## ⚠️有了分布式缓存为什么还要设计本地缓存？

主要是为了解决redis热key的问题。





## ⚠️如何解决redis热key问题

1、多级缓存

2、热key备份

3、热key拆分



## ⚠️千万用户的连续签到数据你准备怎么存储









## ✅如何避免库存扣减的超卖/少卖问题

解决超卖/少卖的问题，其实本质上是在解决并发问题，那如何解决并发问题呢？我们很容易想到的，就是要控制库存扣减时的原子性和有序性。小七面试的时候，被问过，如果只在MySQL数据库层面处理，你准备怎么做？所以我们先来看看，如果只在数据库进行扣减应该怎么做。

**数据库**

我们可以考虑加锁，下面是一个`悲观锁`的例子：

```mysql
-- 1. 开启事务  
START TRANSACTION;  
  
-- 2. 加锁行  
SELECT quantity   
FROM products   
WHERE id = 1   
FOR UPDATE;  
  
-- 此时其他事务将无法修改 id=1 的这一行，直到当前事务结束  
  
-- 3. 执行更新  
UPDATE products   
SET quantity = quantity - 10   
WHERE id = 1;  
  
-- 4. 提交事务  
COMMIT;
```

当然也可以考虑使用`乐观锁`，下面是一个简单的例子：

在应用程序中，首先需要读取需要更新的记录及其版本号

```mysql
UPDATE products SET price = 19.99, version = version + 1 WHERE id = 1 AND version = v1;
```

在应用程序中，根据业务需求对读取到的数据进行修改，然后尝试更新数据库中的记录。在更新语句中，通过版本号来确保只有在版本号与预期一致时才执行更新操作。

```mysql
UPDATE products SET price = 19.99, version = version + 1 WHERE id = 1 AND version = v1;
```

但是加锁这种方式不适用于高并发的情况，一个是MySQL自身的性能瓶颈，一个是加锁会造成阻塞排队的情况（注意：悲观锁在update的时候，也是要加行级锁的）。

为了高性能和高并发，我们可以考虑借助缓存的力量，这里咱们使用Redis来扣减库存。

**Redis**

我们可以在redis中基于lua脚本来做库存扣减（注：lua脚本在redis中的执行是原子的）。

首先，从Redis获取当前剩余库存量；接着，检查该库存是否足以进行扣减；若充足，则执行扣减操作；若不足，则返回库存不足的提示。示例如下：

```lua
-- 输入参数  
local stock_key = KEYS[1]  -- 库存键名  
local quantity_to_deduct = tonumber(ARGV[1])  -- 要扣减的数量  
  
-- 获取当前库存量  
local current_stock = tonumber(redis.call('GET', stock_key))  
  
-- 检查库存是否足够扣减  
if current_stock >= quantity_to_deduct then  
    -- 足够扣减，更新库存量  
    local new_stock = current_stock - quantity_to_deduct  
    redis.call('SET', stock_key, new_stock)  
    return 'Stock deducted successfully. New stock level: ' .. new_stock  
else  
    -- 库存不足，返回错误信息  
    return 'Insufficient stock. Current stock level: ' .. current_stock  
end
```

使用了Redis后，会有数据一致性的问题，这里就不展开了。



## ✅MySQL怎么做热点数据高效更新?

如何有效应对高并发的热点数据更新问题，特别是像库存扣减这样的情况，有一些解决方案可供考虑：

**缓存优化**：通过合理利用缓存技术，如Redis等，将热点数据缓存起来，减少直接对数据库的访问压力，提高读取效率。
**分库分表**：可以考虑对热点数据进行分库分表存储，将数据分散存储在不同的数据库实例中，从而降低单一数据库的压力。
**异步处理**：将热点数据的更新操作异步化，例如通过消息队列，将更新请求先暂存起来，然后异步处理，减少直接对数据库的并发访问。
**乐观锁**：使用乐观锁机制，在更新数据时先进行版本号比对，避免多个并发请求同时修改同一条数据，降低数据更新冲突的概率。
**业务拆分**：根据业务特点，将热点数据进行合理拆分，减少对同一份数据的频繁更新操作，从而降低热点集中度。

那针对MySQL的话，我们业类有以下方案：

**方案一**
拆分库存，将原本的大库存分解为多个小库存，这样一次扣减操作可以分散到不同的库或表中进行，从而降低锁的粒度，提高并发性。优点：实施简单直接。
缺点：可能导致碎片问题，同时库存调控会变得不够便捷。

**方案二**
请求合并策略：将多个库存扣减请求合并为一个请求，以实现批量更新的操作。优点：操作简单，易于实施。
缺点：适用于异步场景或在经过详细分析后确定可合并的情况。

**方案三**
Update转换为Insert：通过直接插入一条占用记录的方式，将更新操作转换为插入操作，然后通过异步统计剩余库存或通过SQL统计流水方式计算剩余库存。

优点：避免了Update操作，减少了锁冲突。
缺点：插入时控制不当容易导致超卖情况，而且插入后剩余库存统计可能会变得困难。

**方案四**

使用高级数据库特性
原理：利用数据库的高级特性来优化热点数据的更新性能。
实施方式：如MySQL的热点更新自动检测功能（某些云数据库已支持），可以自动检测并处理热点行的更新操作，减少锁竞争和并发性能下降。



参考文章：https://cloud.tencent.com/developer/article/2395586